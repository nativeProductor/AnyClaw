基于 OpenClaw 源码分析和行业最新方案（Mem0 / Zep / Letta / A-Mem）调研，设计的AnyClaw记忆系统设计。
一、设计选型
不以单一系统为蓝本，而是组合取长——用 OpenClaw 的工程框架、Mem0 的隔离体系、Letta 的版本管理、Zep 的知识图谱、A-Mem 的自进化能力。
能力
最佳参考
原因
整体插件架构
OpenClaw
成熟的 Plugin-First 工程框架，可扩展性最好
用户记忆隔离
Mem0
三级隔离（agent / user / session）设计最完善
工作经验沉淀
Letta Context Repositories
Git 版本化知识管理，可更新可回溯
领域知识结构化
Zep / Graphiti
知识图谱能表达实体关系，不只是文本碎片
经验自进化
A-Mem
新知识能触发旧知识更新，记忆会"活"起来

---
二、核心概念：五层记忆架构
整个平台围绕五层记忆设计，从下到上逐层叠加：类比理解——想象你招了一个新员工：
层
类比
示例
Layer 1 · 岗位人设
他的岗位说明书
"你是财务报销专员"
Layer 2 · 工作经验
他入职培训学到的公司制度
"一线城市住宿标准 600 元/晚"
Layer 3 · 用户记忆
他对每个同事的印象
"张三总是忘贴发票"
Layer 4 · 会话上下文
他今天和某个人的具体对话
"张三正在问北京出差报销"
Layer 5 · 程序性记忆
他积累的办事套路
"查报销进度要先确认工单号格式"

---
三、Layer 1：岗位人设（开发者配置）
解决需求：开发者设定AnyClaw的岗位职责、基础素养、人设这是AnyClaw的"出厂设置"，由开发者在管理后台配置。
3.1 配置结构
岗位职责示例（做什么）
- 帮助员工处理报销申请
- 解答公司报销政策相关问题
- 引导员工填写正确的报销单据
基础素养示例（怎么做）
- 回答要准确，涉及金额时必须引用政策原文
- 遇到不确定的问题，引导用户联系财务部
- 保护用户隐私，不透露其他用户的报销信息
安全边界示例（不能做什么）：
- 不得泄露其他用户的任何信息
- 不得编造不存在的政策
- 不得执行超出职责范围的操作
3.2 技术实现
- 参考 OpenClaw 的 JSON5 配置驱动 + Zod 验证
- 人设配置转化为结构化的 System Prompt，注入每次对话的最前面
- 配置有版本号，修改后即时生效——新会话自动使用最新版，进行中的会话在下一轮对话时切换
3.3 人设完整性保护（SHA-256）
人设文件是 Agent 角色边界的根基。发布岗位人设时计算 SHA-256 hash 并写入数据库，Heartbeat 自省任务每次启动前校验——防止 Agent 在自省或 Skill 生成过程中悄然修改自己的角色边界。
- 岗位人设只能通过开发者管理界面修改（Agent 无操作权限）
- 修改后系统自动重新计算并存储新 hash
- Hash 校验失败：阻止本次自省 + 向开发者发出告警

---
四、Layer 2：工作经验（Agent 在线教育平台）
解决需求：通过"在线教育平台"让 Agent 自我学习领域知识，沉淀为对所有用户生效的工作经验
这是整个方案最关键的创新点。传统 RAG 是"给一堆文档，搜到哪段读哪段"。我们要做的是让 Agent 像人一样"学会"——把文档知识内化为结构化的工作经验。
4.1 培训素材管理
开发者 / 培训师上传公司知识材料：
素材类型
示例
政策文档
《2026年差旅报销管理办法》.pdf
常见问题
FAQ-报销.xlsx
案例库
过往优秀回答记录
更新通知
"2月起住宿标准从500调整为600"
关联知识
组织架构图、审批流程图
4.2 学习流程：培训 → 考核 → 上岗
4.3 经验卡片结构
每条"工作经验"不是原始文档碎片，而是 Agent 内化后的结构化知识卡片：
经验卡片 #0042
┌─────────────────────────────────────────┐
│ 标题：一线城市住宿报销标准                 │
│ 内容：北京/上海/广州/深圳，                │
│       住宿标准上限 600元/晚（2026年2月起） │
│ 来源：《2026年差旅报销管理办法》第三章第二节│
│ 关联实体：[一线城市] [住宿标准] [差旅报销] │
│ 关联卡片：#0038(职级差异) #0041(超标审批)  │
│ 版本：v2（2026-02-01 从500更新为600）      │
│ 置信度：高（来自正式文件）                  │
│ 标签：政策规则                             │
└─────────────────────────────────────────┘




三个关键设计点：
卡片间有链接参考 A-Mem 的 Zettelkasten 设计。查到一条经验能顺藤摸瓜找到所有关联知识。比如查到"住宿标准"，自动关联到"职级差异"和"超标审批流程"。
每张卡片有版本历史参考 Letta Context Repositories 的 Git 版本管理。政策更新时旧版本不丢失，可以回溯"以前的标准是什么"。
新知识触发旧卡片更新参考 A-Mem 自进化机制。住宿标准从 500 改为 600 时，关联的"超标审批"卡片自动被标记需要复核。
4.4 知识更新流程

---
4.5 Layer 2 检索精度与成本管理
Layer 2 是每次对话中 input token 的最大单一来源（典型占比约 53%）。Top-K 检索注入大量卡片，但模型实际引用的往往只是其中一部分——未被引用的卡片消耗 Token 却不带来价值。
检索效率指标
Layer 2 检索效率 = cited_tokens（被模型引用的卡片 Token 数）
                 / injected_tokens（本次注入的全部卡片 Token 数）




健康目标：检索效率 ≥ 0.65。**引用标记机制（零 LLM 成本）**每张知识卡片注入时，在内容开头自动添加引用标记前缀：
[CITE:0042] 一线城市住宿报销标准：北京/上海/广州/深圳，上限 600 元/晚（2026年2月起）




任务结束时，task_complete 钩子扫描模型输出，匹配所有出现的 [CITE:XXXX] 编号，零成本统计 cited_count 与 uncited_count，写入 TaskCostRecord。僵尸卡片检测
检测条件：retrieved_count ≥ 10  AND  cited_rate < 5%




僵尸卡片消耗 Token 却不被引用，系统自动标记 zombie_flag = true，停止向该卡片发起检索，并在管理界面提示开发者复查（内容是否过时？是否与其他卡片高度重叠？）。动态 K 值调整Top-K 的 K 值按 task_pattern 维度独立跟踪，当某类任务检索效率持续低于阈值时自动减小 K（减少注入），效率高时适当增大 K（引入更多潜在相关知识）：
检索效率趋势
调整操作
连续 3 次 < 0.5
K = max(K−1, 1)
连续 5 次 > 0.8
K = min(K+1, K_max)
其他
不变
完整成本观测框架（per-layer Token 归因、soul_reflection 成本分析、成本优化开关）见 → AnyClaw — 成本观测与优化体系

---
五、Layer 3：用户记忆（隔离层）
解决需求：每个用户会话相互隔离，用户之间无法通过 prompt 让 agent 泄露他人信息每个用户拥有独立的记忆空间：
记忆类型
示例
偏好
"习惯用发票拍照上传，不喜欢手动填写"
历史
"上次报销 2月10日的北京出差，审批中"
上下文
"正在处理一笔 3200 元的培训费报销"
沟通风格
"喜欢简短回答，不要长篇大论"
5.1 三道安全防线
用户隔离是本方案的安全底线，通过三道防线确保：
5.2 用户记忆生命周期

---
六、Layer 4：会话上下文（临时层）
单次对话的临时工作记忆。上下文管理采用 5 阶段渐进式压缩引擎，对长期运行的AnyClaw全程用户无感知：
阶段
触发阈值
策略
备注
1
70%
压缩工具调用结果（去除 verbose 输出）
无感知
2
80%
将旧 Turn 摘要压缩为 1-2 句话
无感知
3
85%
LLM 批量摘要（每 10 个 Turn → 1 段摘要）
无感知
4
90%
Checkpoint 存储 + 重置上下文（仅保留摘要）
无感知
5
95%
紧急截断，保留最近 N 轮
无感知
Stage 4 对应原有 Pre-Compaction Flush，将其从"兜底机制"提前为"第 4 阶段正常策略"，大幅降低触发截断的概率。
七、Layer 5：程序性记忆（自省归纳）
解决需求：从实际执行中自动归纳可复用任务步骤，为 Skill 自生成提供数据支撑Layer 5 不需要开发者手动维护——每次任务完成，自省系统自动从会话上下文中提取步骤序列并写入。
7.1 数据结构
CREATE TABLE procedural_memory (
  id TEXT PRIMARY KEY,
  task_pattern TEXT,         -- "查询报销进度"
  steps JSON,                -- ["获取工单号", "调用查询接口", "解读状态码"]
  success_count INTEGER DEFAULT 0,
  failure_count INTEGER DEFAULT 0,
  avg_turn_count REAL,       -- 平均需要几轮对话完成
  last_outcome TEXT,
  created_at TEXT,
  updated_at TEXT
);




7.2 读写时机
操作
触发时机
条件
写入
task_complete 钩子
每次任务完成后自动提取步骤序列
读取
新任务开始前
按 task_pattern 匹配，注入 success_count ≥ 3 的步骤作为提示
触发 Skill 提案
Heartbeat soul_reflection
success_count ≥ 10 且 success_rate ≥ 80%
7.3 五层 Token Budget 优先级
各层 token 预算按优先级分配，低优先级层未用完的 budget 自动向高优先级层滚动：
working（当前 session）> episodic（事件日志）> semantic（知识图谱）
> procedural（可复用步骤）> user_memory（用户偏好）




7.4 生命周期
Layer 5 通过 success_rate 自然衰减，同时配合显式清理规则：
状态
触发条件
处理
stale（低置信过期）
success_count < 5 且 60 天无更新
停止注入，软删除
deprecated（失效）
近 10 次执行 failure_rate > 50%
停止注入，保留用于原因分析
promoted（晋升为 Skill）
对应 Skill 发布后
进入 archived 状态，继续接收执行反馈以检测 Skill 漂移
manual reset
开发者主动触发
按 task_pattern 前缀批量作废，用于业务流程大改版
与 Layer 2 的定位关系：两者均为 Agent 全局共享知识，但 Layer 2 是陈述性知识（是什么），Layer 5 是程序性知识（怎么做）。Layer 5 排在 Layer 4 之后而非 Layer 2 之后，原因有二：
1. 程序性步骤提示需紧邻当前会话注入才最有效；
2. Layer 5 由执行自动生成，生命周期与 Layer 3/4 更接近（动态积累、自动过期），而非像 Layer 2 那样由人工训练维护。

---
八、五层联动：一次完整对话
以**"员工张三问报销问题"**为例：
张三："我上个月去北京出差，住宿花了 650 元，能报销吗？"
九、"Agent 在线教育平台"产品形态
面向开发者 / 培训师的管理界面：
素材库
- 上传文档（PDF / Word / Excel）
- 导入 FAQ 问答对
- 录入实际案例
- 素材版本管理
学习任务
- 创建学习计划（指定素材范围）
- 监控学习进度（提取中 / 已完成）
- 触发增量学习（仅学新增内容）
- 查看学习日志
经验库
- 查看全部经验卡片
- 编辑 / 修订卡片内容
- 知识图谱可视化（查看关联关系）
- 版本对比（diff 视图）
考核中心
- 设置考核题库（手动 + 自动出题）
- 运行模拟考核
- 查看考核报告（通过率、薄弱点）
- 一键发布上线
四个关键交互流程：
场景
流程
首次培训
上传素材 → 系统自动提取知识点 → 生成经验卡片草稿 → 培训师审核确认 → 考核 → 发布
政策更新
上传新版文档 → 系统高亮变更点 → 自动更新关联经验 → 培训师确认 → 发布
考核验证
系统根据经验库自动生成测试问题 → Agent 作答 → 评分报告 → 未通过标记薄弱点
经验浏览
知识图谱视图展示经验卡片间的关联关系，点击卡片查看详情和版本历史

---
十、安全架构
安全维度
防护措施
参考方案
用户间隔离
物理分区 + 查询隔离 + 输出审查（三道防线）
Mem0 三级隔离
Prompt 注入防护
正则模式检测 + 拒绝响应 + 告警日志
OpenClaw LanceDB 插件
知识泄露防护
Agent 不暴露内部经验卡片原始内容，只用自己的话回答
自研
人设篡改防护
System Prompt 不可被用户消息覆盖，多轮越狱检测 + SHA-256 完整性校验
自研 + Automaton
审计追溯
所有经验变更有版本历史，用户对话可选留痕
Letta Git 版本管理
数据合规
支持"忘记我"（GDPR 删除），用户记忆保留期限可配置
Mem0 GDPR 合规

---
十一、技术选型建议
组件
推荐方案
理由
整体框架
基于 OpenClaw 二次开发 或 自建
Plugin 架构成熟，通道丰富（41+ 消息通道）
经验存储
Graphiti (Neo4j) + Vector DB
知识图谱 + 语义检索双通道
用户记忆
Mem0 开源版 或 自建 SQLite / PostgreSQL
三级隔离方案成熟
程序性记忆
自建 SQLite（参考 Automaton procedural_memory）
轻量、与主库同库，查询简单
经验版本管理
Git-based（参考 Letta MemFS）
可回溯、可 diff、可协作
经验自进化
A-Mem 思路自研
新知识触发关联更新
检索引擎
Hybrid（BM25 + Vector + Graph）
OpenClaw 的检索管线 + 图遍历
安全层
自研（参考 OpenClaw 注入检测）
三道防线缺一不可
上下文压缩
5 阶段渐进式压缩引擎（参考 Automaton compression-engine.ts）
全程无感知，比单一截断策略平滑

---
十二、岗位对齐与记忆边界
完整的岗位对齐度定义、公式及跨系统调控机制，见：AnyClaw — 岗位对齐度评估体系本章聚焦记忆系统视角：各层的漂移风险、写入时的边界校验、以及对齐分下降时记忆系统的响应。
12.1 各层漂移风险画像
层
漂移类型
典型场景
当前防护
Layer 1 岗位人设
基准篡改
Agent 在自省中修改角色边界
✅ SHA-256 完整性校验（3.3 节）
Layer 2 工作经验
知识边界扩散
培训材料包含岗位外内容 → 知识卡片实体超范围
⚠️ 写入时实体标签校验（见 12.2）
Layer 3 用户记忆
用户诱导偏移
用户反复引导越界 → 越界行为被记为习惯
⚠️ 写入时工具白名单校验（见 12.2）
Layer 4 会话上下文
单会话内短暂漂移
长对话末尾被引导出边界
✅ 会话结束自动清空，不跨会话
Layer 5 程序性记忆
步骤范围蔓延
自动归纳的步骤包含越界工具调用
⚠️ 写入时工具白名单校验（见 12.2）
12.2 写入时的前向边界校验
每次向记忆层写入内容时，在持久化之前执行边界校验，阻止越界内容进入记忆体：各层校验规则：
记忆层
校验项
判定标准
超界时处理
Layer 2 知识卡片
实体标签与岗位关键词集的覆盖率
覆盖率 < 40% → 严重超界；40%~60% → 轻度超界
严重：拒绝写入；轻度：pending_review
Layer 3 用户习惯
习惯行为对应的工具是否在岗位工具白名单内
工具不在白名单 → 超界
不写入习惯，仅记录日志
Layer 5 程序步骤
steps 中所有工具调用是否在岗位工具白名单内
任一工具不在白名单 → 超界
写入但标记 boundary_warning，不注入提示，不计入 success_count 晋升条件
12.3 对齐分下降时的记忆响应
岗位对齐分（JAS）由 Heartbeat soul_reflection 计算。分数下降时，记忆系统按级别响应：
JAS 范围
记忆系统响应
≥ 0.8
正常运行，所有层正常读写
[0.6, 0.8)
告警状态。输出归因报告（定位最可疑层），其余正常
[0.4, 0.6)
暂停 Layer 5 自动写入；暂停 Layer 2 增量学习；Layer 3 写入降为保守模式（仅记录用户明确表达的偏好，忽略行为归纳）；要求开发者确认后恢复
< 0.4
冻结 Layer 2、Layer 5 所有写入；Layer 3 只读；通知开发者人工介入
12.4 归因分析：定位是哪一层导致了漂移
Heartbeat 告警时自动生成归因报告，帮助开发者快速定位根因：
归因报告（JAS: 0.82 → 0.58，触发告警）
──────────────────────────────────────────
Jaccard 下降（0.91 → 0.72）—— 越界能力分析：
  检测到越界能力标签：[组织架构查询, HR员工信息]
  Layer 5 贡献：pattern "查员工信息" 含 hr_api.get_employee（30次成功）
  Layer 3 贡献：用户"李四"记忆中含"习惯查询组织架构"（12次记录）
  Layer 2 贡献：知识卡片 #0089 实体含"员工归属部门"（与 HR 域重叠）

Recall 无明显变化（0.90 → 0.88）—— 职责覆盖正常

根因判断：Layer 5 为主要驱动（贡献 67%），Layer 3 为次要驱动

建议操作：
  ① 清除 L5：task_pattern LIKE '查%员工%' 的所有记录
  ② 检查 L3 李四的记忆，删除越界习惯条目
  ③ 复核 L2 知识卡片 #0089，确认是否需要撤回





---
附录：参考资料
- OpenClaw 记忆系统深度分析（本项目前置研究）
- AI Agent 记忆系统方案对比（2026）（本项目前置研究）
- Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory
- Zep: A Temporal Knowledge Graph Architecture for Agent Memory
- Letta Context Repositories: Git-based Memory for Coding Agents
- A-Mem: Agentic Memory for LLM Agents (NeurIPS 2025)
- Conway Research/automaton（Procedural Memory / Compression Engine / SHA-256 宪法保护参考）
- AnyClaw — 成本观测与优化体系（Layer 2 检索精度、引用标记机制、per-layer Token 归因参考）

---
Changelog
版本
日期
变更内容
变更原因
v1.0
2026-02-25
初始版本，基于 OpenClaw / Mem0 / Zep / Letta / A-Mem 设计四层记忆架构
—
v1.1
2026-02-27
架构升级为五层（新增 Layer 5 程序性记忆）；Layer 1 增加 SHA-256 完整性保护（3.3 节）；Layer 4 升级为 5 阶段渐进式压缩引擎；技术选型表新增程序性记忆和压缩引擎条目
基于 Automaton (Conway Research) 调研，补充自动步骤归纳、人设防篡改、长会话无损压缩能力
v1.2
2026-02-27
Layer 5 新增 7.4 生命周期节（stale / deprecated / promoted / manual reset 四种清理规则）；新增 Layer 5 与 Layer 2 定位关系说明
设计评审：Layer 5 缺少过期清理机制；明确程序性记忆与陈述性记忆的互补关系及 Layer 5 排序原因
v1.3
2026-02-27
新增第十二章「岗位对齐与记忆边界」：各层漂移风险画像、写入时前向边界校验规则、JAS 分级响应机制、归因分析报告结构；关联岗位对齐度评估体系独立文档
设计评审：记忆变更直接驱动 Agent 行为，需要从记忆系统视角建立对齐度治理机制
v1.4
2026-02-27
新增 4.5 节「Layer 2 检索精度与成本管理」：引用标记机制（[CITE:XXXX]）、检索效率指标（cited/injected ≥ 0.65）、僵尸卡片检测规则、动态 K 值调整；附录新增成本文档引用
成本思维设计评审：Layer 2 是最大 input token 来源，缺少检索精度管理机制，无法追踪哪些卡片被实际使用
